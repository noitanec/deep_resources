# deep_resources
Links to study material and code related to machine / deep learning.

<details>
<summary> machine-learning </summary>
  
  + [SMOTE: Synthetic Minority Oversampling Technique](https://towardsdatascience.com/smote-fdce2f605729)
  + [f1-score](https://towardsdatascience.com/the-f1-score-bec2bbc38aa6)
</details>

<details>
<summary> transformer </summary>
  
  + [TRANSFORMERS FROM SCRATCH](http://peterbloem.nl/blog/transformers)
  + [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
  + [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
</details>

<details>
<summary> DeBERTa </summary>
  
  + [DeBERTa: Decoding-enhanced BERT with Disentangled Attention (Machine Learning Paper Explained)
](https://www.youtube.com/watch?v=_c6A33Fg5Ns)
</details>

<details>
<summary> RNN </summary>
  
  + [Difference between hidden dimension and n_layers in rnn using pytorch](https://stackoverflow.com/questions/63294347/difference-between-hidden-dimension-and-n-layers-in-rnn-using-pytorch#:~:text=Hidden%20dimension%20determines%20the%20feature,the%20upper%20layer(vertical).)
  + [RNN from Scratch](https://github.com/pangolulu/rnn-from-scratch)
</details>
